{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.1.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchnlp.nn as nnnlp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "import os\n",
    "import nltk, re, pprint\n",
    "import nltk.tokenize as tk\n",
    "from collections import Counter\n",
    "import time\n",
    "import ast\n",
    "import sentencepiece as spm\n",
    "#%cd /scratch/jic286/johnsonlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train('--input=E:/Documents/JohnsonLab/RawNoteText.txt --model_prefix=SentencePiece32k --vocab_size=32000 --character_coverage=1.0 --model_type=unigram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = tk.RegexpTokenizer(r'[a-zA-Z]+')\n",
    "cleaned = tkn.tokenize(line)\n",
    "# test = (tkn.tokenize(text[0][:1]))\n",
    "# \" \".join(test)\n",
    "# type(original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = pd.Series(data=cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482867816"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"corpuscleaned.txt\", \"w\")\n",
    "f.write(str(cleaned)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned.to_csv(r'corpuscleaned.txt',sep=\" \", index=False, header=False)\n",
    "\n",
    "UNK = \"<UNK>\"\n",
    "PAD = \"<PAD>\"\n",
    "def build_vocab(sentences, min_count=3, max_vocab=None):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences (list of strings)\n",
    "    \"\"\"\n",
    "    # keep track of the number of appearance of each word\n",
    "    word_count = Counter()\n",
    "    \n",
    "    for s in sentences:\n",
    "        word_count.update(re.findall(r\"[\\w']+|[.,!?;]\", s.lower()))\n",
    "    \n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return vocabulary, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortEmbeddings(path, emb_dim = 50):\n",
    "    \n",
    "\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        glove_embedding = []\n",
    "        words = {}\n",
    "        chars = {}\n",
    "        idx2words = {}\n",
    "        ordered_words = []\n",
    "    \n",
    "        for i, line in tqdm(enumerate(f)):\n",
    "            s = line.split()\n",
    "            glove_embedding.append(np.asarray(s[1:]))\n",
    "            \n",
    "            words[s[0]] = len(words)\n",
    "            idx2words[i] = s[0]\n",
    "            ordered_words.append(s[0])\n",
    "\n",
    "        \n",
    "    # add unknown to word and char\n",
    "    glove_embedding.append(np.random.rand(emb_dim))\n",
    "    words[\"<UNK>\"] = len(words)\n",
    "    \n",
    "    # add padding\n",
    "    glove_embedding.append(np.zeros(emb_dim))\n",
    "    words[\"<PAD>\"] = len(words)\n",
    "    \n",
    "    chars[\"<UNK>\"] = len(chars)\n",
    "    chars[\"<PAD>\"] = len(chars)\n",
    "    \n",
    "    glove_embedding = np.array(glove_embedding).astype(float)\n",
    "    return glove_embedding, words, idx2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Admission Date:  [**2151-7-16**]       Discharge Date:  [**2151-8-4**]\\n\\n\\nService:\\nADDENDUM:\\n\\nRADIOLOGIC STUDIES:  Radiologic studies also included a chest\\nCT, which confirmed cavitary lesions in the left lung apex\\nconsistent with infectious process/tuberculosis.  This also\\nmoderate-sized left pleural effusion.\\n\\nHEAD CT:  Head CT showed no intracranial hemorrhage or mass\\neffect, but old infarction consistent with past medical\\nhistory.\\n\\nABDOMINAL CT:  Abdominal CT showed lesions of\\nT10 and sacrum most likely secondary to osteoporosis. These can\\nbe followed by repeat imaging as an outpatient.\\n\\n\\n\\n                            [**First Name8 (NamePattern2) **] [**First Name4 (NamePattern1) 1775**] [**Last Name (NamePattern1) **], M.D.  [**MD Number(1) 1776**]\\n\\nDictated By:[**Hospital 1807**]\\nMEDQUIST36\\n\\nD:  [**2151-8-5**]  12:11\\nT:  [**2151-8-5**]  12:21\\nJOB#:  [**Job Number 1808**]\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = pd.read_csv('mimic/NOTEEVENTS.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"',low_memory=False, encoding='utf-8')\n",
    "notes['TEXT'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SEQ_NUM</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1298</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1299</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1300</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1301</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
       "0    1297         109   172335      1.0     40301\n",
       "1    1298         109   172335      2.0       486\n",
       "2    1299         109   172335      3.0     58281\n",
       "3    1300         109   172335      4.0      5855\n",
       "4    1301         109   172335      5.0      4254"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnoses =pd.read_csv('mimic/DIAGNOSES_ICD.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"',low_memory=False, encoding='utf-8')\n",
    "diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CGID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>WARNING</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>RESULTSTATUS</th>\n",
       "      <th>STOPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "      <td>7657</td>\n",
       "      <td>121183.0</td>\n",
       "      <td>297945.0</td>\n",
       "      <td>3411</td>\n",
       "      <td>2172-03-14 11:00:00</td>\n",
       "      <td>2172-03-14 11:52:00</td>\n",
       "      <td>16446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotStopd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>7657</td>\n",
       "      <td>121183.0</td>\n",
       "      <td>297945.0</td>\n",
       "      <td>3411</td>\n",
       "      <td>2172-03-14 13:00:00</td>\n",
       "      <td>2172-03-14 12:36:00</td>\n",
       "      <td>16446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotStopd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>713</td>\n",
       "      <td>7657</td>\n",
       "      <td>121183.0</td>\n",
       "      <td>297945.0</td>\n",
       "      <td>3411</td>\n",
       "      <td>2172-03-14 15:00:00</td>\n",
       "      <td>2172-03-14 15:10:00</td>\n",
       "      <td>14957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotStopd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>714</td>\n",
       "      <td>7657</td>\n",
       "      <td>121183.0</td>\n",
       "      <td>297945.0</td>\n",
       "      <td>3411</td>\n",
       "      <td>2172-03-14 17:00:00</td>\n",
       "      <td>2172-03-14 17:01:00</td>\n",
       "      <td>16446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotStopd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>715</td>\n",
       "      <td>7657</td>\n",
       "      <td>121183.0</td>\n",
       "      <td>297945.0</td>\n",
       "      <td>3411</td>\n",
       "      <td>2172-03-14 19:00:00</td>\n",
       "      <td>2172-03-14 19:29:00</td>\n",
       "      <td>14815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotStopd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID  ICUSTAY_ID  ITEMID            CHARTTIME  \\\n",
       "0     711        7657  121183.0    297945.0    3411  2172-03-14 11:00:00   \n",
       "1     712        7657  121183.0    297945.0    3411  2172-03-14 13:00:00   \n",
       "2     713        7657  121183.0    297945.0    3411  2172-03-14 15:00:00   \n",
       "3     714        7657  121183.0    297945.0    3411  2172-03-14 17:00:00   \n",
       "4     715        7657  121183.0    297945.0    3411  2172-03-14 19:00:00   \n",
       "\n",
       "             STORETIME   CGID VALUE VALUEUOM  WARNING  ERROR  RESULTSTATUS  \\\n",
       "0  2172-03-14 11:52:00  16446   NaN     Date      NaN    NaN           NaN   \n",
       "1  2172-03-14 12:36:00  16446   NaN     Date      NaN    NaN           NaN   \n",
       "2  2172-03-14 15:10:00  14957   NaN     Date      NaN    NaN           NaN   \n",
       "3  2172-03-14 17:01:00  16446   NaN     Date      NaN    NaN           NaN   \n",
       "4  2172-03-14 19:29:00  14815   NaN     Date      NaN    NaN           NaN   \n",
       "\n",
       "    STOPPED  \n",
       "0  NotStopd  \n",
       "1  NotStopd  \n",
       "2  NotStopd  \n",
       "3  NotStopd  \n",
       "4  NotStopd  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(diagnoses['SUBJECT_ID'])/(len(diagnoses['ICD9_CODE'].unique()))\n",
    "dates=pd.read_csv('mimic/DATETIMEEVENTS.csv.gz')\n",
    "'12assfdsfasfas'[:3]\n",
    "\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "####THIS IS THE ONE THAT WORKS FOR CONVERTING THE NOTES'CATEGORIES TO LABELS\n",
    "\n",
    "testnotes = notes[~notes['ISERROR'].notnull() & notes['CATEGORY'].notnull() & notes['DESCRIPTION'].notnull() & notes['HADM_ID'].notnull()]\n",
    "testnotes['ISERROR'] = testnotes['ISERROR'].fillna(0)\n",
    "testnotes = testnotes[['TEXT', 'CATEGORY', 'SUBJECT_ID','HADM_ID']]\n",
    "\n",
    "#BINARY\n",
    "#classes = pd.read_csv('binary_class_labels.csv').iloc[:, 1:3]\n",
    "#FULL\n",
    "classes = pd.read_csv('class_labels.csv')\n",
    "\n",
    "classes = dict(zip(classes['Category'].values, classes['Group'].values))\n",
    "testnotes['CATEGORY'] = testnotes['CATEGORY'].apply(lambda x: classes[x])\n",
    "#14 and 3 are the same, more or less, so let's combine them\n",
    "testnotes['CATEGORY'].replace(14, 3, inplace=True)\n",
    "\n",
    "#testnotes['CATEGORY'].unique()\n",
    "testnotes['HADM_ID'] = testnotes['HADM_ID'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "      <td>0</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853</td>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "      <td>0</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "      <td>0</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118</td>\n",
       "      <td>5533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "      <td>0</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489</td>\n",
       "      <td>4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "      <td>0</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453</td>\n",
       "      <td>V4581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  CATEGORY  SUBJECT_ID  \\\n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...         0       22532   \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...         0       13702   \n",
       "2  Admission Date:  [**2119-5-4**]              D...         0       13702   \n",
       "3  Admission Date:  [**2124-7-21**]              ...         0       13702   \n",
       "4  Admission Date:  [**2162-3-3**]              D...         0       26880   \n",
       "\n",
       "   HADM_ID ICD9_CODE  \n",
       "0   167853      2113  \n",
       "1   107527       311  \n",
       "2   167118      5533  \n",
       "3   196489      4019  \n",
       "4   135453     V4581  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "testnotes = testnotes.loc[testnotes['HADM_ID'].isin(diagnoses['HADM_ID'])]\n",
    "ID2ICD9 = dict(zip(diagnoses['HADM_ID'].values, diagnoses['ICD9_CODE'].values))\n",
    "testnotes['ICD9_CODE'] = testnotes['HADM_ID'].apply(lambda x:ID2ICD9[x] )\n",
    "\n",
    "testnotes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes.to_csv(\"RawNoteText.txt\", sep=\"\\n\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning ICD-9 codes to binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICD2binary(code):\n",
    "    '''\n",
    "    Helper function to convert ICD9 codes to binary labels based on whether or not they indicate cancer or not\n",
    "    '''\n",
    "    if(isinstance(code, str)):\n",
    "        #check for non-numeric code starts\n",
    "        if(code[0].isdigit() == False):\n",
    "            return 2\n",
    "        if(code[0]=='0'):\n",
    "            return 2\n",
    "        #only scan first 3 digits of remaining code\n",
    "        if(len(code)>3):\n",
    "            code = ast.literal_eval(code[:3])\n",
    "        else:\n",
    "            code = ast.literal_eval(code)\n",
    "        #check for non-neoplasm codes\n",
    "        if((code<140)|(code>229)):\n",
    "            \n",
    "            return 2\n",
    "        if((code>=140) & (code<=209)):\n",
    "        #return positive value for malignancies\n",
    "            return 1\n",
    "        # all else are benign \n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testnotes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-40726722d95c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#testnotes['LABEL'] = testnotes['ICD9_CODE'].apply(lambda x: ICD2binary(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtestnotes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestnotes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestnotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LABEL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testnotes' is not defined"
     ]
    }
   ],
   "source": [
    "#testnotes['LABEL'] = testnotes['ICD9_CODE'].apply(lambda x: ICD2binary(x))\n",
    "testnotes.head()\n",
    "subset = testnotes.loc[testnotes['LABEL']!=2]\n",
    "sample = subset.sample(frac=1, random_state=0)\n",
    "print(len(sample))\n",
    "sample.groupby('LABEL').count()['TEXT']/len(sample) * 100\n",
    "#sample.to_csv('MIMIC_neoplasms.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reloading previously saved .csv\n",
    "sample = pd.read_csv('MIMIC_neoplasms.csv')\n",
    "sample.head()\n",
    "sample = sample.sample(frac=.2, random_state=0)\n",
    "sample['LABEL'].value_counts()\n",
    "len(sample['TEXT'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    103\n",
      "0     66\n",
      "Name: LABEL, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    787\n",
       "0    725\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(sample, test_size=0.10, random_state=1)\n",
    "train_X, train_y = train_data['TEXT'], train_data['LABEL']\n",
    "test_X, test_y = test_data['TEXT'], test_data['LABEL']\n",
    "\n",
    "test_data.groupby('LABEL').count()['TEXT']/len(test_data) * 100\n",
    "print(test_data['LABEL'].value_counts())\n",
    "train_data['LABEL'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-014c14aa894a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-014c14aa894a>\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(sentences, min_count, max_vocab)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     for s in sentences:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         word_count.update(re.findall(r\"[\\w']+|[.,!?;]\", s.lower()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mword_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[\\w']+|[.,!?;]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_count\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mUNK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPAD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "UNK = \"<UNK>\"\n",
    "PAD = \"<PAD>\"\n",
    "def build_vocab(sentences, min_count=3, max_vocab=None):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences (list of strings)\n",
    "    \"\"\"\n",
    "    # keep track of the number of appearance of each word\n",
    "    word_count = Counter()\n",
    "    \n",
    "#     for s in sentences:\n",
    "#         word_count.update(re.findall(r\"[\\w']+|[.,!?;]\", s.lower()))\n",
    "    sentences.apply(lambda x:  word_count.update(re.findall(r\"[\\w']+|[.,!?;]\", x.lower())))\n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return vocabulary, indices\n",
    "    \n",
    "vocabulary, vocab_indices = build_vocab(train_X)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155102it [00:02, 68299.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# load embedding\n",
    "emb_dim = 50\n",
    "with open('vectors.txt') as f:\n",
    "    glove_embedding = []\n",
    "    words = {}\n",
    "    chars = {}\n",
    "    idx2words = {}\n",
    "    ordered_words = []\n",
    "\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        s = line.split()\n",
    "        glove_embedding.append(np.asarray(s[1:]))\n",
    "        \n",
    "        words[s[0]] = len(words)\n",
    "        idx2words[i] = s[0]\n",
    "        ordered_words.append(s[0])\n",
    "        \n",
    "# add unknown to word and char\n",
    "glove_embedding.append(np.random.rand(emb_dim))\n",
    "words[\"<UNK>\"] = len(words)\n",
    "\n",
    "# add padding\n",
    "glove_embedding.append(np.zeros(emb_dim))\n",
    "words[\"<PAD>\"] = len(words)\n",
    "\n",
    "chars[\"<UNK>\"] = len(chars)\n",
    "chars[\"<PAD>\"] = len(chars)\n",
    "\n",
    "glove_embedding = np.array(glove_embedding).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_padded_index_sequences(words, sentences, pad_length=100):\n",
    "    padded_sequences = np.zeros((len(sentences), pad_length))\n",
    "    for i, s in enumerate(sentences):\n",
    "        indices = np.ones(pad_length) * words['<PAD>']\n",
    "        # only take the first pad_length tokens\n",
    "        token_indices = np.array([words[w] if w in words else words['<UNK>'] for w in re.findall(r\"[\\w']+|[.,!?;]\", s.lower())[:pad_length]])\n",
    "        indices[:len(token_indices)] = token_indices\n",
    "        padded_sequences[i] = indices\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = sentences_to_padded_index_sequences(words, train_data['TEXT'], 2000)\n",
    "test_X = sentences_to_padded_index_sequences(words, test_data['TEXT'], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 1839 \n",
      " True Negatives: 0 \n",
      " False Positive: 12 \n",
      " False Negatives:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-e8ec722d2ec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"True Positives: {} \\n True Negatives: {} \\n False Positive: {} \\n False Negatives:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y, reorder)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mCompute\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mrecall\u001b[0m \u001b[0mpairs\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \"\"\"\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             raise TypeError(\"Expected sequence or array-like, got %s\" %\n\u001b[1;32m--> 138\u001b[1;33m                             type(x))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'float'>"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "len(train_X)\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(len(predictions)):\n",
    "    if(predictions[i] != truths[i]):\n",
    "        if(predictions ==0):\n",
    "            fn+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    else:\n",
    "        if(predictions == 0):\n",
    "            tn +=1\n",
    "        else:\n",
    "            tp +=1\n",
    "tpr = (tp /(tp + fn))\n",
    "\n",
    "fpr = (fp/(tn + fp))\n",
    "            \n",
    "print(\"True Positives: {} \\n True Negatives: {} \\n False Positive: {} \\n False Negatives:{}\".format(tp, tn, fp, fn))\n",
    "print('AUC: {}'.format(metrics.auc(fpr, tpr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996237862696217"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('AUC: {}'.format(metrics.auc(fpr, tpr)))\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(truths, predictions)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MIMICDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = sentences.astype(int)\n",
    "        self.labels = np.array(labels).astype(int)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return (torch.LongTensor(self.sentences[key]), self.labels[key])\n",
    "#model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, nclasses, dropout)\n",
    "#model = model.cuda()\n",
    "#\n",
    "#model.train()\n",
    "train_loader = DataLoader(MIMICDataset(train_X, train_y),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(MIMICDataset(test_X, test_y),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "torch.manual_seed(111)\n",
    "\n",
    "i=0\n",
    "# for batch in train_loader:\n",
    "\n",
    "        \n",
    "#     x = batch[0].to(device)\n",
    "#     y = batch[1]\n",
    "#     model(x)\n",
    "#     model.zero_grad()\n",
    "\n",
    "#     break\n",
    "#     #print(i)\n",
    "#     i+=1\n",
    "    \n",
    "\n",
    "#print(y)\n",
    "#print(len(glove_embedding))\n",
    "\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "nclasses = 2\n",
    "#out = model(x)\n",
    "#print(out[0].shape, out[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self.fc = nn.Linear(ntoken * 2000, nclasses)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        #print(\"input: {}\".format(src.device))\n",
    "        #if(src.device == \"cpu\"):\n",
    "        src = src.cuda()\n",
    "\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            #print(\"src device: {}\".format(src.device))\n",
    "\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "        #print(\"mask: {}\".format(self.src_mask.device))\n",
    "#         if(self.encoder.weight.device == \"cpu\"):\n",
    "#             print(\"cpu error\")\n",
    "#         if(self.encoder.padding_idx != None):\n",
    "#             if(self.encoder.padding_idx.device != \"cuda\"):\n",
    "#                 print(self.encoder.padding_idx.device)\n",
    "        #print(\"encoder: {}\".format(src.device))\n",
    "        src = self.encoder(src)\n",
    "        src = src * math.sqrt(self.ninp)\n",
    "        #print(\"sqrt: {}\".format(src.device))\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        #print(\"positional encoder: {}\".format(src.device))\n",
    "\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        #print(\"transformer encoder: {}\".format(output.device))\n",
    "\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        #print(\"decoder: {}\".format(output.device))\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        output = self.fc(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        #output = self.softmax(output)\n",
    "        return output\n",
    "# print(torch.cuda.is_available())\n",
    "# #model(x.to(device)).device\n",
    "\n",
    "# class AttnDecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "#         super(AttnDecoderRNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.dropout_p = dropout_p\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#         self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "#         self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "#         self.dropout = nn.Dropout(self.dropout_p)\n",
    "#         self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "#         self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "#     def forward(self, input, hidden, encoder_outputs):\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "#         embedded = self.dropout(embedded)\n",
    "\n",
    "#         attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "#         output = F.relu(output)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "\n",
    "#         output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "#         return output, hidden, attn_weights\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "#x = torch.Tensor(32, 100).normal_() * 155103/3\n",
    "#x = x.long()\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"A single attention head\"\"\"\n",
    "    def __init__(self, d_model, d_feature, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We will assume the queries, keys, and values all have the same feature size\n",
    "        self.attn = ScaledDotProductAttention(dropout)\n",
    "        self.query_tfm = nn.Linear(d_model, d_feature)\n",
    "        self.key_tfm = nn.Linear(d_model, d_feature)\n",
    "        self.value_tfm = nn.Linear(d_model, d_feature)\n",
    " \n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        Q = self.query_tfm(queries) # (Batch, Seq, Feature)\n",
    "        K = self.key_tfm(keys) # (Batch, Seq, Feature)\n",
    "        V = self.value_tfm(values) # (Batch, Seq, Feature)\n",
    "        # compute multiple attention weighted sums\n",
    "        x = self.attn(Q, K, V)\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"The full multihead attention block\"\"\"\n",
    "    def __init__(self, d_model, d_feature, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_feature = d_feature\n",
    "        self.n_heads = n_heads\n",
    "        # in practice, d_model == d_feature * n_heads\n",
    "        assert d_model == d_feature * n_heads\n",
    " \n",
    "        # Note that this is very inefficient:\n",
    "        # I am merely implementing the heads separately because it is \n",
    "        # easier to understand this way\n",
    "        self.attn_heads = nn.ModuleList([\n",
    "            AttentionHead(d_model, d_feature, dropout) for _ in range(n_heads)\n",
    "        ])\n",
    "        self.projection = nn.Linear(d_feature * n_heads, d_model) \n",
    "     \n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        log_size(queries, \"Input queries\")\n",
    "        x = [attn(queries, keys, values, mask=mask) # (Batch, Seq, Feature)\n",
    "             for i, attn in enumerate(self.attn_heads)]\n",
    "         \n",
    "        # reconcatenate\n",
    "        x = torch.cat(x, dim=Dim.feature) # (Batch, Seq, D_Feature * n_heads)\n",
    "        log_size(x, \"concatenated output\")\n",
    "        x = self.projection(x) # (Batch, Seq, D_Model)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, rnn='LSTM', k=2):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.conv = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=k)\n",
    "        self.pool = nn.MaxPool1d(1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.rnn_fn = rnn\n",
    "        assert self.rnn_fn in ['LSTM', 'RNN', 'ATTN']\n",
    "        self.rnn = getattr(nn, rnn)(embedding_dim, hidden_dim, batch_first=True)\n",
    "        #self.attn = \n",
    "        self.linear = nn.Linear(hidden_dim, 1000)\n",
    "        self.fc = nn.Linear(1000, output_dim)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state values\n",
    "        \"\"\"\n",
    "        hidden = nn.Parameter(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "        #print(hidden)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            c = nn.Parameter(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "            \n",
    "            return hidden, c\n",
    "        #if(self.rnn_fn =='ATTN')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #if([x.shape[0], x.shape[1]] != [32, 100]):\n",
    "            #print(x.shape)\n",
    "        x = x.to(device)\n",
    "\n",
    "        #print(x.shape, \" input\")\n",
    "        x = self.emb(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        #print(x.shape, \" permute 1\")\n",
    "        #x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        #print(x.shape, \" conv\")\n",
    "\n",
    "        #x = self.pool(x)\n",
    "        #print(x.shape, \" pool\")\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        #x = x.squeeze()\n",
    "        #print(x.shape, \" permute 2\") \n",
    "\n",
    "\n",
    "       # print(x.shape)\n",
    "        #x = x.reshape(x.shape[0], -1, self.embedding_dim)\n",
    "        #self.hidden_dim = 50\n",
    "        #self.rnn.hidden_dim = self.hidden_dim\n",
    "        #self.rnn.input_dim = self.hidden_dim\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(x.shape, \" embedding\")\n",
    "        _, last_hidden = self.rnn(x, self.init_hidden(x.shape[0]))\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            last_hidden = last_hidden[0]\n",
    "       # print(last_hidden.shape, \" memory\")\n",
    "        last_hidden = self.linear(last_hidden)\n",
    "        last_hidden = self.relu(last_hidden)\n",
    "        out = self.fc(last_hidden)\n",
    "        #out = self.relu(out)\n",
    "\n",
    "       # print(out.shape, \" output\")\n",
    "        return out\n",
    "    \n",
    "#print(x)\n",
    "model = RNN(40, 2, len(glove_embedding), 50, rnn='LSTM')\n",
    "#model.emb.weight.data.copy_(torch.from_numpy(glove_embedding))\n",
    "\n",
    "#print(model(x))\n",
    "# torch.Size([32, 100])  input\n",
    "# torch.Size([32, 100, 50])  embedding\n",
    "# torch.Size([1, 32, 40])  memory\n",
    "# torch.Size([1, 32, 2])  output\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DUPLICATE WITHOUT CNN\n",
    "### RETOOLED FOR ATTENTION\n",
    "# x = torch.Tensor(32, 100).normal_() * 155103/3\n",
    "# x = x.long()\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, rnn='LSTM'):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #self.e,ed\n",
    "        self.rnn_fn = rnn\n",
    "        assert self.rnn_fn in ['LSTM', 'RNN', 'ATTN']\n",
    "        self.rnn = getattr(nn, rnn)(embedding_dim, hidden_dim, batch_first=True)\n",
    "        #self.rnn = nnnlp.Attention()\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state values\n",
    "        \"\"\"\n",
    "        hidden = nn.Parameter(torch.zeros(1, batch_size, self.hidden_dim)).to(device)\n",
    "        #print(hidden)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            c = nn.Parameter(torch.zeros(1, batch_size, self.hidden_dim)).to(device)\n",
    "            \n",
    "            return hidden, c\n",
    "        #if(self.rnn_fn =='ATTN')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #if([x.shape[0], x.shape[1]] != [32, 100]):\n",
    "            #print(x.shape)\n",
    "        x = x.cuda()\n",
    "\n",
    "        #print(x.shape, \" input\")\n",
    "        x = self.emb(x)\n",
    "        #rint(x.shape)\n",
    "        #x = x.unsqueeze(1)\n",
    "        #x= self.conv(x)\n",
    "        #x = self.pool(x)\n",
    "        #x= self.relu(x)\n",
    "        #x = x.squeeze()\n",
    "        #print(x.shape)\n",
    "        \n",
    "\n",
    "       # print(x.shape)\n",
    "        #x = x.reshape(x.shape[0], -1, 32)\n",
    "        #self.hidden_dim = 32\n",
    "        #self.rnn.hidden_dim = self.hidden_dim\n",
    "        #self.rnn.input_dim = self.hidden_dim\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(x.shape, \" embedding\")\n",
    "        out, last_hidden = self.rnn(x, self.init_hidden(x.shape[0]))\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            last_hidden = last_hidden[0]\n",
    "       # print(last_hidden.shape, \" memory\")\n",
    "        #out = self.fc(last_hidden)\n",
    "       # print(out.shape, \" output\")\n",
    "        return out, last_hidden\n",
    "    \n",
    "#print(x)\n",
    "model = RNNEncoder(40, 2, len(glove_embedding), 50, rnn='LSTM')\n",
    "\n",
    "#model.emb.weight.data.copy_(torch.from_numpy(glove_embedding))\n",
    "\n",
    "#print(model(x))\n",
    "# torch.Size([32, 100])  input\n",
    "# torch.Size([32, 100, 50])  embedding\n",
    "# torch.Size([1, 32, 40])  memory\n",
    "# torch.Size([1, 32, 2])  output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test = 0\n",
    "def train(model, train_loader, test_loader, \n",
    "          learning_rate=0.005, num_epoch=10, print_every=100):\n",
    "    # Training steps\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            #print(\"batch {}, data shape {P} \".format(i, data.shape))\n",
    "            labels = labels.to(device)\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            model.zero_grad()\n",
    "            #print(outputs.shape, labels.shape)\n",
    "\n",
    "            loss = loss_fn(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(loss)\n",
    "\n",
    "             # report performance\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print('Train set | epoch: {:3d}/{} | {:6d}/{:6d} batches | Loss: {:6.4f}'.format(\n",
    "                    epoch + 1, num_epoch, i + 1, len(train_loader), loss.item()))     \n",
    "#                 print('Epoch: [{0}/{1}], Step: [{2}/{3}], Loss: {4}, Validation Acc:{5}, AUC:{6}'.format(\n",
    "#                     epoch + 1, EPOCHS, i + 1, len(train_loader), loss.data[0], test_acc, test_auc))\n",
    "        \n",
    "    # Evaluate after every epoch\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        truths = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, labels) in enumerate(test_loader):\n",
    "                outputs = model(data)\n",
    "#                 import ipdb; ipdb.set_trace()\n",
    "#                 predicted = ((outputs > 0.5).long()).view(-1)\n",
    "                pred = outputs.data.max(1)[1]\n",
    "                \n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred.cpu() == labels.long()).sum()\n",
    "                \n",
    "            acc = (100.0 * correct / total)\n",
    "#             fpr, tpr, thresholds = metrics.roc_curve(truths, predictions)\n",
    "#             auc = metrics.auc(fpr, tpr)\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "           # print('Test set | Accuracy: {:6.4f} | AUC: {:4.2f} | time elapse: {:>9}'.format(\n",
    "           #     acc, auc, elapse))\n",
    "            print('Test set | Epoch: {} | Accuracy: {:.2f} | time elapse: {:>9}'.format(epoch+1, \n",
    "                acc, elapse))\n",
    "    return model, predictions, truths ##save this for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW TRAINING LOOP\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10, evaluate =False):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_dim, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if(evaluate):\n",
    "                total += labels.size(0)\n",
    "                correct += (pred.cpu() == labels.long()).sum()\n",
    "                \n",
    "\n",
    "                \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    acc = (100.0 * correct / total)\n",
    "#             fpr, tpr, thresholds = metrics.roc_curve(truths, predictions)\n",
    "#             auc = metrics.auc(fpr, tpr)\n",
    "    #elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "   # print('Test set | Accuracy: {:6.4f} | AUC: {:4.2f} | time elapse: {:>9}'.format(\n",
    "   #     acc, auc, elapse))\n",
    "    print('Test set | Epoch: {} | Accuracy: {:.2f}'.format(epoch+1, \n",
    "        acc))\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters,train_loader, test_loader num_epochs = 10, print_every=5000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "#                       for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    for epoch in num_epochs:\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for batch in train_loader:\n",
    "            i+=1\n",
    "    #        training_pair = training_pairs[iter - 1]\n",
    "    #        input_tensor = training_pair[0]\n",
    "    #        target_tensor = training_pair[1]\n",
    "            input_tensor = batch[0]\n",
    "            target_tensor = batch[1]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        for batch\n",
    "            \n",
    "    # Evaluate after every epoch\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        truths = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, labels) in enumerate(test_loader):\n",
    "                outputs = model(data)\n",
    "#                 import ipdb; ipdb.set_trace()\n",
    "#                 predicted = ((outputs > 0.5).long()).view(-1)\n",
    "                pred = outputs.data.max(1)[1]\n",
    "                \n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred.cpu() == labels.long()).sum()\n",
    "                \n",
    "            acc = (100.0 * correct / total)\n",
    "#             fpr, tpr, thresholds = metrics.roc_curve(truths, predictions)\n",
    "#             auc = metrics.auc(fpr, tpr)\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "           # print('Test set | Accuracy: {:6.4f} | AUC: {:4.2f} | time elapse: {:>9}'.format(\n",
    "           #     acc, auc, elapse))\n",
    "            print('Test set | Epoch: {} | Accuracy: {:.2f} | time elapse: {:>9}'.format(epoch+1, \n",
    "                acc, elapse))\n",
    "\n",
    "        return encoder, decoder, plot_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7564, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851, 1)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "n_classes = 1\n",
    "# Binarize the output\n",
    "y_score = label_binarize(predictions, classes=np.arange(n_classes))\n",
    "y_test = label_binarize(truths, classes=np.arange(n_classes))\n",
    "\n",
    "print(y_test.shape)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    print(i)\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "lw = 2\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', ])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='AUC of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "0      2.864725\n",
       "1      2.199209\n",
       "2     10.039456\n",
       "3     50.217645\n",
       "4      6.784873\n",
       "5      0.259714\n",
       "6      0.045767\n",
       "7      1.522407\n",
       "8      0.451425\n",
       "9      0.395525\n",
       "10     0.127792\n",
       "11     0.004850\n",
       "12     0.004706\n",
       "13    25.081905\n",
       "Name: TEXT, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testnotes= testnotes.sample(frac=0.05, random_state=0)\n",
    "#testnotes['CATEGORY'].unique()\n",
    "\n",
    "testnotes.groupby('CATEGORY').count()['TEXT']/len(testnotes) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.16 GiB (GPU 0; 8.00 GiB total capacity; 4.89 GiB already allocated; 806.50 MiB free; 343.94 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b1543abaebed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#model.encoder.weight.data.copy_(torch.from_numpy(glove_embedding).to(device))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-bf81a221d865>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, test_loader, learning_rate, num_epoch, print_every)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m#print(loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.16 GiB (GPU 0; 8.00 GiB total capacity; 4.89 GiB already allocated; 806.50 MiB free; 343.94 MiB cached)"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "CUDA_LAUNCH_BLOCKING=0\n",
    "BATCH_SIZE = 1\n",
    "train_loader = DataLoader(MIMICDataset(train_X, train_y),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(MIMICDataset(test_X, test_y),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "torch.manual_seed(111)\n",
    "# glove_model = RNN(40, 2, len(glove_embedding), 50, rnn='LSTM', k=2)\n",
    "# glove_model = glove_model.to(device)\n",
    "\n",
    "ntokens = len(glove_embedding)# the size of vocabulary\n",
    "\n",
    "emsize = 50 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.5 # the dropout value\n",
    "nclasses = 2\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, nclasses, dropout)\n",
    "model.encoder.weight.data.copy_(torch.from_numpy(glove_embedding))\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "#model.encoder.weight.data.copy_(torch.from_numpy(glove_embedding).to(device))\n",
    "\n",
    "model, predictions, truths = train(model, train_loader=train_loader, test_loader=test_loader, learning_rate = 0.1e-4, num_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: Int64Index.data is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: GPU pinned 1  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: Index.data is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: GPU pinned 8  2\n",
      "Tensor: GPU pinned 8  2\n",
      "Tensor: GPU pinned 8  2\n",
      "Tensor: GPU pinned 5000  1  200\n",
      "Tensor: GPU pinned 8  8\n",
      "Parameter: GPU pinned 155104  200\n",
      "Parameter: GPU pinned 155104  200\n",
      "Parameter: GPU pinned 155104\n",
      "Parameter: GPU pinned 2  15510400\n",
      "Parameter: GPU pinned 2\n",
      "Parameter: GPU pinned 600  200\n",
      "Parameter: GPU pinned 600\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 600  200\n",
      "Parameter: GPU pinned 600\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Tensor: GPU pinned 8  100  200\n",
      "Tensor: GPU pinned 8  100  200\n",
      "Tensor: GPU pinned 8\n",
      "Tensor: GPU pinned 8  100\n",
      "Tensor: GPU pinned 2\n",
      "Tensor: GPU pinned 2\n",
      "Tensor: GPU pinned 2  15510400\n",
      "Tensor: GPU pinned 2  15510400\n",
      "Tensor: GPU pinned 155104\n",
      "Tensor: GPU pinned 155104\n",
      "Tensor: GPU pinned 155104  200\n",
      "Tensor: GPU pinned 155104  200\n",
      "Tensor: GPU pinned 155104  200\n",
      "Tensor: GPU pinned 155104  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 600\n",
      "Tensor: GPU pinned 600\n",
      "Tensor: GPU pinned 600  200\n",
      "Tensor: GPU pinned 600  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 200  200\n",
      "Tensor: GPU pinned 600\n",
      "Tensor: GPU pinned 600\n",
      "Tensor: GPU pinned 600  200\n",
      "Tensor: GPU pinned 600  200\n",
      "Tensor: GPU pinned \n",
      "Tensor: GPU pinned \n",
      "Tensor: GPU pinned 8  2\n",
      "Tensor: GPU pinned 8\n",
      "Tensor: GPU pinned 8  100\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 600\n",
      "Parameter: GPU pinned 600  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 200\n",
      "Parameter: GPU pinned 200  200\n",
      "Parameter: GPU pinned 600\n",
      "Parameter: GPU pinned 600  200\n",
      "Parameter: GPU pinned 2\n",
      "Parameter: GPU pinned 2  15510400\n",
      "Parameter: GPU pinned 155104\n",
      "Parameter: GPU pinned 155104  200\n",
      "Parameter: GPU pinned 155104  200\n",
      "Tensor: GPU pinned 8  8\n",
      "Tensor: GPU pinned 5000  1  200\n",
      "Total size: 377127836\n"
     ]
    }
   ],
   "source": [
    "#subset, k=3\n",
    "# Test set | Epoch: 0 | Accuracy: 59.0000 | time elapse:  00:00:11\n",
    "# Test set | Epoch: 1 | Accuracy: 52.0000 | time elapse:  00:00:22\n",
    "# Test set | Epoch: 2 | Accuracy: 52.0000 | time elapse:  00:00:34\n",
    "# Test set | Epoch: 3 | Accuracy: 66.0000 | time elapse:  00:00:45\n",
    "# Test set | Epoch: 4 | Accuracy: 69.0000 | time elapse:  00:00:55\n",
    "# Test set | Epoch: 5 | Accuracy: 58.0000 | time elapse:  00:01:04\n",
    "# Test set | Epoch: 6 | Accuracy: 71.0000 | time elapse:  00:01:14\n",
    "# Test set | Epoch: 7 | Accuracy: 72.0000 | time elapse:  00:01:23\n",
    "# Test set | Epoch: 8 | Accuracy: 70.0000 | time elapse:  00:01:33\n",
    "# Test set | Epoch: 9 | Accuracy: 64.0000 | time elapse:  00:01:43\n",
    "torch.cuda.is_available()\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "#k=4\n",
    "# Train set | epoch:   1/10 |    100/   237 batches | Loss: 0.7166\n",
    "# Train set | epoch:   1/10 |    200/   237 batches | Loss: 0.3979\n",
    "# Test set | Epoch: 1 | Accuracy: 74.0000 | time elapse:  00:00:08\n",
    "# Train set | epoch:   2/10 |    100/   237 batches | Loss: 0.3456\n",
    "# Train set | epoch:   2/10 |    200/   237 batches | Loss: 0.4418\n",
    "# Test set | Epoch: 2 | Accuracy: 80.0000 | time elapse:  00:00:17\n",
    "# Train set | epoch:   3/10 |    100/   237 batches | Loss: 0.0871\n",
    "# Train set | epoch:   3/10 |    200/   237 batches | Loss: 0.1620\n",
    "# Test set | Epoch: 3 | Accuracy: 80.0000 | time elapse:  00:00:26\n",
    "# Train set | epoch:   4/10 |    100/   237 batches | Loss: 0.0428\n",
    "# Train set | epoch:   4/10 |    200/   237 batches | Loss: 0.0070\n",
    "# Test set | Epoch: 4 | Accuracy: 77.0000 | time elapse:  00:00:35\n",
    "# Train set | epoch:   5/10 |    100/   237 batches | Loss: 0.0042\n",
    "# Train set | epoch:   5/10 |    200/   237 batches | Loss: 0.0432\n",
    "# Test set | Epoch: 5 | Accuracy: 78.0000 | time elapse:  00:00:44\n",
    "# Train set | epoch:   6/10 |    100/   237 batches | Loss: 0.0078\n",
    "# Train set | epoch:   6/10 |    200/   237 batches | Loss: 0.0751\n",
    "# Test set | Epoch: 6 | Accuracy: 80.0000 | time elapse:  00:00:54\n",
    "# Train set | epoch:   7/10 |    100/   237 batches | Loss: 0.0047\n",
    "# Train set | epoch:   7/10 |    200/   237 batches | Loss: 0.0414\n",
    "# Test set | Epoch: 7 | Accuracy: 79.0000 | time elapse:  00:01:03\n",
    "# Train set | epoch:   8/10 |    100/   237 batches | Loss: 0.0024\n",
    "# Train set | epoch:   8/10 |    200/   237 batches | Loss: 0.0015\n",
    "# Test set | Epoch: 8 | Accuracy: 78.0000 | time elapse:  00:01:12\n",
    "# Train set | epoch:   9/10 |    100/   237 batches | Loss: 0.0012\n",
    "# Train set | epoch:   9/10 |    200/   237 batches | Loss: 0.0069\n",
    "# Test set | Epoch: 9 | Accuracy: 78.0000 | time elapse:  00:01:20\n",
    "# Train set | epoch:  10/10 |    100/   237 batches | Loss: 0.0131\n",
    "# Train set | epoch:  10/10 |    200/   237 batches | Loss: 0.0016\n",
    "# Test set | Epoch: 10 | Accuracy: 79.0000 | time elapse:  00:01:29\n",
    "\n",
    "#torch.cuda.max_memory_allocated(0)#-torch.cuda.memory_allocated(0)\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()\n",
    "\n",
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \"  \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s  %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n",
    "\n",
    "dump_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(glove_model.state_dict(), r'E:\\Documents\\Johnson Lab\\model_weights_12-17-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\Jehuty\\\\AppData\\\\Roaming', 'ASL.LOG': 'Destination=file', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'ANUBIS', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'CONDA_BAT': 'E:\\\\Program Files\\\\Anaconda3\\\\condabin\\\\conda.bat', 'CONDA_DEFAULT_ENV': 'base', 'CONDA_EXE': 'E:\\\\Program Files\\\\Anaconda3\\\\Scripts\\\\conda.exe', 'CONDA_PREFIX': 'E:\\\\Program Files\\\\Anaconda3', 'CONDA_PROMPT_MODIFIER': '(base) ', 'CONDA_PYTHON_EXE': 'E:\\\\Program Files\\\\Anaconda3\\\\python.exe', 'CONDA_SHLVL': '1', 'CUDA_PATH': 'E:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.1', 'CUDA_PATH_V10_1': 'E:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.1', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'GTK_BASEPATH': 'C:\\\\Program Files (x86)\\\\GtkSharp\\\\2.12\\\\', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\Jehuty', 'LOCALAPPDATA': 'C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\ANUBIS', 'NUMBER_OF_PROCESSORS': '4', 'NVCUDASAMPLES10_1_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v10.1', 'NVCUDASAMPLES_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v10.1', 'NVTOOLSEXT_PATH': 'E:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\', 'ONEDRIVE': 'C:\\\\Users\\\\Jehuty\\\\OneDrive', 'ONEDRIVECONSUMER': 'C:\\\\Users\\\\Jehuty\\\\OneDrive', 'OS': 'Windows_NT', 'PATH': 'E:\\\\Program Files\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\lib;E:\\\\Program Files\\\\Anaconda3\\\\Library\\\\bin;E:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\bin\\\\x64;E:\\\\Program Files\\\\Anaconda3;E:\\\\Program Files\\\\Anaconda3\\\\Library\\\\mingw-w64\\\\bin;E:\\\\Program Files\\\\Anaconda3\\\\Library\\\\usr\\\\bin;E:\\\\Program Files\\\\Anaconda3\\\\Library\\\\bin;E:\\\\Program Files\\\\Anaconda3\\\\Scripts;E:\\\\Program Files\\\\Anaconda3\\\\bin;E:\\\\Program Files\\\\Anaconda3\\\\condabin;E:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.1\\\\bin;E:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.1\\\\libnvvp;C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\System32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Program Files (x86)\\\\GtkSharp\\\\2.12\\\\bin;C:\\\\Program Files\\\\MATLAB\\\\R2017a\\\\runtime\\\\win64;C:\\\\Program Files\\\\MATLAB\\\\R2017a\\\\bin;E:\\\\Program Files\\\\Anaconda3;E:\\\\Program Files\\\\Anaconda3\\\\Scripts;E:\\\\Program Files\\\\Anaconda3\\\\Library\\\\bin;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\WINDOWS\\\\System32\\\\OpenSSH;E:\\\\Program Files\\\\PuTTY;E:\\\\Program Files\\\\NVIDIA Corporation\\\\Nsight Compute 2019.4.0;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;E:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local\\\\Programs\\\\EmEditor;C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;E:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.2.2\\\\bin;.;C:\\\\Users\\\\Jehuty\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages\\\\numpy\\\\.libs', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 94 Stepping 3, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '5e03', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'E:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PROMPT': '(base) $P$G', 'PSMODULEPATH': 'E:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYCHARM': 'E:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.2.2\\\\bin;', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'TEMP': 'C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\Jehuty\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'ANUBIS', 'USERDOMAIN_ROAMINGPROFILE': 'ANUBIS', 'USERNAME': 'Jehuty', 'USERPROFILE': 'C:\\\\Users\\\\Jehuty', 'VS140COMNTOOLS': 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\Common7\\\\Tools\\\\', 'WINDIR': 'C:\\\\WINDOWS', 'JPY_INTERRUPT_EVENT': '2640', 'IPY_INTERRUPT_EVENT': '2640', 'JPY_PARENT_PID': '2652', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})\n",
      "1\n",
      "0\n",
      "24468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.py\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "\n",
    "print(os.environ)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(os.getpid())\n",
    "sys.stdout.flush()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "a = torch.randn(10, 10, device=device)\n",
    "c\n",
    "os.system('nvidia-smi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
